# í•„ìš”í•œ library
import streamlit as st

from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS 
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI 
from langchain.schema import HumanMessage, SystemMessage #prompt ë„£ì–´ì¤„ ë•Œ ì“°ëŠ” ê²ƒ
from langchain.callbacks.base import BaseCallbackHandler #í† í° ë‹¨ìœ„ë¡œ ë°›ìë§ˆì ë°”ë¡œ ì¶œë ¥í•˜ê¸°.
from langchain.schema import ChatMessage #ì™”ë‹¤ê°”ë‹¤ í•˜ëŠ” ë©”ì„¸ì§€ë¥¼ ê´€ë¦¬í•˜ëŠ” ê¸°ëŠ¥.

from dotenv import load_dotenv #ë‚´ë¶€ì ìœ¼ë¡œ í† í°ì„ ì¸ì‹í•´ì„œ í•˜ëŠ” ê³¼ì •.

load_dotenv()

# handle streaming conversation
class StreamHandler(BaseCallbackHandler): #ì™”ë‹¤ê°”ë‹¤ í•˜ëŠ” ë©”ì„¸ì§€ë¥¼ ê´€ë¦¬í•˜ëŠ” ì½”ë“œ.
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text)


# function to extract text from an HWP file. í•œê¸€ë¬¸ì„œëŠ” ê·¸ëŒ€ë¡œ ë‹¤ë£¨ëŠ” ê²ƒì´ í•„ìš”í•¨. langchainì—ì„œëŠ” hwp parserë¥¼ ë‹¤ë£° ìˆ˜ ì—†ë‹¤.
import olefile 
import zlib
import struct

def get_hwp_text(filename):
    f = olefile.OleFileIO(filename)
    dirs = f.listdir()

    # HWP íŒŒì¼ ê²€ì¦
    if ["FileHeader"] not in dirs or \
       ["\x05HwpSummaryInformation"] not in dirs:
        raise Exception("Not Valid HWP.")

    # ë¬¸ì„œ í¬ë§· ì••ì¶• ì—¬ë¶€ í™•ì¸
    header = f.openstream("FileHeader")
    header_data = header.read()
    is_compressed = (header_data[36] & 1) == 1

    # Body Sections ë¶ˆëŸ¬ì˜¤ê¸°
    nums = []
    for d in dirs:
        if d[0] == "BodyText":
            nums.append(int(d[1][len("Section"):]))
    sections = ["BodyText/Section"+str(x) for x in sorted(nums)]

    # ì „ì²´ text ì¶”ì¶œ
    text = ""
    for section in sections:
        bodytext = f.openstream(section)
        data = bodytext.read()
        if is_compressed:
            unpacked_data = zlib.decompress(data, -15)
        else:
            unpacked_data = data
    
        # ê° Section ë‚´ text ì¶”ì¶œ    
        section_text = ""
        i = 0
        size = len(unpacked_data)
        while i < size:
            header = struct.unpack_from("<I", unpacked_data, i)[0]
            rec_type = header & 0x3ff
            rec_len = (header >> 20) & 0xfff

            if rec_type in [67]:
                rec_data = unpacked_data[i+4:i+4+rec_len]
                section_text += rec_data.decode('utf-16')
                section_text += "\n"

            i += 4 + rec_len

        text += section_text
        text += "\n"

    return text

# Function to extract text from an PDF file
from pdfminer.high_level import extract_text

def get_pdf_text(filename):
    raw_text = extract_text(filename)
    return raw_text

# document preprocess
def process_uploaded_file(uploaded_file): #splití•´ì„œ ì €ì¥í•˜ëŠ” ê²ƒì€ í•œë²ˆí•˜ê³  ì•ˆí•˜ê²Œ í•˜ê¸° ìœ„í•´!
    # Load document if file is uploaded
    if uploaded_file is not None:
        # loader

        # splitter
        
        # storage
                
        return vectorstore, raw_text
    return None

# generate response using RAG technic
def generate_response(query_text, vectorstore, callback): #vectorstoreë¥¼ í•´ì„œ ê°€ì ¸ì™€ì„œ cosine ìœ ì‚¬ë„ë¥¼ ë´ì„œ topKë¥¼ ê°€ì ¸ì˜¤ê²Œ.

    # retriever 
        
    # generator
    
    # chaining
    
    return response.content


def generate_summarize(raw_text, callback):

    return response.content

#ì–´í”Œ ê¾¸ë¯¸ëŠ” ì½”ë“œ
# page title
st.set_page_config(page_title='ğŸ¦œğŸ”— ë¬¸ì„œ ê¸°ë°˜ ìš”ì•½ ë° QA ì±—ë´‡')
st.title('ğŸ¦œğŸ”— ë¬¸ì„œ ê¸°ë°˜ ìš”ì•½ ë° QA ì±—ë´‡')

# enter token
import os
api_key = st.sidebar.text_input("Enter your OpenAI API Key", type="password")
save_button = st.sidebar.button("Save Key")
if save_button and len(api_key)>10:
    os.environ["OPENAI_API_KEY"] = api_key
    st.sidebar.success("API Key saved successfully!")

# file upload
uploaded_file = st.file_uploader('Upload an document', type=['hwp','pdf'])

# file upload logic
if uploaded_file:
    vectorstore, raw_text = process_uploaded_file(uploaded_file)
    if vectorstore:
        st.session_state['vectorstore'] = vectorstore
        st.session_state['raw_text'] = raw_text
        
# chatbot greetings
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        ChatMessage(
            role="assistant", content="ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ë¬¸ì„œì— ëŒ€í•œ ì´í•´ë¥¼ ë„ì™€ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ì–´ë–¤ê²Œ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"
        )
    ]

# conversation history print ëˆ„ì ëœ ëŒ€í™”ë¥¼ ì €ì¥í–ˆë‹¤ê°€ í•œë²ˆì— ë¿Œë ¤ì£¼ëŠ” ê¸°ëŠ¥ì„.
for msg in st.session_state.messages:
    st.chat_message(msg.role).write(msg.content)
    
# message interaction
if prompt := st.chat_input("'ìš”ì•½'ì´ë¼ê³  ì…ë ¥í•´ë³´ì„¸ìš”!"):
    st.session_state.messages.append(ChatMessage(role="user", content=prompt))
    st.chat_message("user").write(prompt)

    with st.chat_message("assistant"):
        stream_handler = StreamHandler(st.empty())
        
        if prompt == "ìš”ì•½":
            response = generate_summarize(st.session_state['raw_text'],stream_handler)
            st.session_state["messages"].append(
                ChatMessage(role="assistant", content=response)
            )
        
        else:
            response = generate_response(prompt, st.session_state['vectorstore'], stream_handler)
            st.session_state["messages"].append(
                ChatMessage(role="assistant", content=response)
            )
